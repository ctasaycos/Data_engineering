{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfdf899",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:01.083918Z",
     "start_time": "2021-12-05T15:34:57.954798Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas            as pd                       # data science essentials\n",
    "import matplotlib.pyplot as plt                      # data visualization\n",
    "import seaborn           as sns                      # enhanced data viz\n",
    "from sklearn.model_selection import train_test_split # train-test split\n",
    "from sklearn.linear_model import LogisticRegression  # logistic regression\n",
    "import statsmodels.formula.api as smf                # logistic regression\n",
    "from sklearn.metrics import confusion_matrix         # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score            # auc score\n",
    "from sklearn.neighbors import KNeighborsClassifier   # KNN for classification\n",
    "from sklearn.neighbors import KNeighborsRegressor    # KNN for regression\n",
    "from sklearn.preprocessing import StandardScaler     # standard scaler\n",
    "from sklearn.tree import DecisionTreeClassifier      # classification trees\n",
    "from sklearn.tree import plot_tree                   # tree plots\n",
    "# loading data\n",
    "file = \"/Users/carlostasaycosilva/Downloads/GOT_character_predictions.xlsx\"\n",
    "got = pd.read_excel(io=  file, na_values= \" ?\")\n",
    "# displaying the head of the dataset and number of non-null\n",
    "print(got.info(), end = \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73547f59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:01.112709Z",
     "start_time": "2021-12-05T15:35:01.086854Z"
    }
   },
   "outputs": [],
   "source": [
    "got.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b922346",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:01.117290Z",
     "start_time": "2021-12-05T15:35:01.115355Z"
    }
   },
   "outputs": [],
   "source": [
    " # THIs has no sense to replace with a mode because obviously it cannot be true replacing with a mode\n",
    "    #dateof birth is the samethat the age\n",
    " #4   dateOfBirth                 433 non-null    float64\n",
    " #5   mother                      21 non-null     object \n",
    " #6   father                      26 non-null     object \n",
    " #7   heir                        23 non-null     object \n",
    " #9   spouse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8310f5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:01.133845Z",
     "start_time": "2021-12-05T15:35:01.119510Z"
    }
   },
   "outputs": [],
   "source": [
    "#Numerical variable replace with the mean\n",
    "#Negatives values are replaced by zero and after that with the mean\n",
    "avg_age = got['age'][got['age']>0].mean()\n",
    "got['age'] = got['age'].apply(lambda x : x if x > 0 else 0)\n",
    "got['age'] = got['age'].apply(lambda x : x if x > 0 else avg_age)\n",
    "#Create a new column only to identify over 18 characters\n",
    "got['over_agemean'] = got['age'].apply(lambda x : 1 if x > avg_age else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512944b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:01.139392Z",
     "start_time": "2021-12-05T15:35:01.135466Z"
    }
   },
   "outputs": [],
   "source": [
    "#Categorical variables replace na with the mode\n",
    "got['title'] = got['title'].fillna(got['title'].mode()[0])\n",
    "got['culture'] = got['culture'].fillna(got['culture'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90e45fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:01.162586Z",
     "start_time": "2021-12-05T15:35:01.155904Z"
    }
   },
   "outputs": [],
   "source": [
    "#Binomial variable will be replace with the mode\n",
    "got['isAliveMother'] = got['isAliveMother'].fillna(got['isAliveMother'].mode()[0])\n",
    "got['isAliveFather'] = got['isAliveFather'].fillna(got['isAliveFather'].mode()[0])\n",
    "got['isAliveHeir'] = got['isAliveHeir'].fillna(got['isAliveHeir'].mode()[0])\n",
    "got['isAliveSpouse'] = got['isAliveSpouse'].fillna(got['isAliveSpouse'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecabbf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:02.090753Z",
     "start_time": "2021-12-05T15:35:01.832278Z"
    }
   },
   "outputs": [],
   "source": [
    "#Deal with title COLUMN\n",
    "#I installed pandasql to manage the dataframe with sql language which is more easy to me than pandas\n",
    "#pip install pandasql\n",
    "import pandasql as ps\n",
    "got_query = \"\"\"SELECT title, count(title) as count_  FROM got group by title order by count_ desc\"\"\"\n",
    "got_house = ps.sqldf(got_query, locals())\n",
    "got_house.head(n=10)\n",
    "#Now we can see which title have more members in the dataset\n",
    "#We will group all titles with less than 30  to other group\n",
    "got[\"title\"] = got[\"title\"].map({\"Ser\":\"Ser\",\"Maester\":'Maester',\"Archmaester\":\"Other_title\",\"Lord\":\"Other_title\",\"Septon\":'Other_title',\"Winterfell\":'Other_title',\"Princess\":'Other_title', \"Lady\":'Other_title', \"Septa\":'Other_title', \"Prince\":'Other_title'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b0e55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:02.567742Z",
     "start_time": "2021-12-05T15:35:02.510931Z"
    }
   },
   "outputs": [],
   "source": [
    "#Deal with HOUSE COLUMN\n",
    "#I installed pandasql to manage the dataframe with sql language which is more easy to me than pandas\n",
    "#pip install pandasql\n",
    "got_query = \"\"\"SELECT title, count(title) as count_  FROM got group by title order by count_ desc\"\"\"\n",
    "got_house = ps.sqldf(got_query, locals())\n",
    "got_house.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5165041a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:03.217951Z",
     "start_time": "2021-12-05T15:35:03.160776Z"
    }
   },
   "outputs": [],
   "source": [
    "#Deal with HOUSE COLUMN\n",
    "#I installed pandasql to manage the dataframe with sql language which is more easy to me than pandas\n",
    "#pip install pandasql\n",
    "got_query = \"\"\"SELECT culture, count(culture) as count_  FROM got group by culture order by count_ desc\"\"\"\n",
    "got_house = ps.sqldf(got_query, locals())\n",
    "got_house.head(n=10)\n",
    "got[\"culture\"] = got[\"culture\"].map({\"Northmen\":\"Northmen\",\"Ironborn\":'Ironborn',\"Free Folk\":\"Free_Folk\",\"Valyrian\":\"Valyrian\",\"Braavosi\":'Braavosi',\"Ghiscari\":'Other_culture',\"Dornish\":'Other_culture', \"Dothraki\":'Other_culture', \"Valemen\":'Other_culture', \"Rivermen\":'Other_culture'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc98c341",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:03.815110Z",
     "start_time": "2021-12-05T15:35:03.812221Z"
    }
   },
   "outputs": [],
   "source": [
    "#Acumulate the houses with lower members to \"Other_house\"\n",
    "#Fill na with other\n",
    "got['house'] = got['house'].fillna('Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a15c61d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:04.518386Z",
     "start_time": "2021-12-05T15:35:04.460015Z"
    }
   },
   "outputs": [],
   "source": [
    "#Deal with HOUSE COLUMN\n",
    "#I installed pandasql to manage the dataframe with sql language which is more easy to me than pandas\n",
    "#pip install pandasql\n",
    "import pandasql as ps\n",
    "got_query = \"\"\"SELECT house, count(house) as count_  FROM got group by house order by count_ desc\"\"\"\n",
    "got_house = ps.sqldf(got_query, locals())\n",
    "got_house.head(n=10)\n",
    "#Now we can see which houses have more members in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a198898",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:05.113239Z",
     "start_time": "2021-12-05T15:35:05.107152Z"
    }
   },
   "outputs": [],
   "source": [
    "got[\"house\"] = got[\"house\"].map({\"Night's Watch\":\"Night_Watch\",\"House Frey\":'House_Frey',\"House Stark\":\"House_Stark\",\"House Targaryen\":\"House_Targaryen\",\"House Lannister\":'House_Lannister',\"House Greyjoy\":'House_Greyjoy',\"House Tyrell\":'House_Tyrell', \"Other\":'Other_house'})\n",
    "got['house'] = got['house'].fillna('Other_house')\n",
    "got[\"house\"] = got[\"house\"].map({\"Night_Watch\":\"Night_Watch\",\"House_Frey\":'House_Frey',\"House_Stark\":\"House_Stark\",\"House_Targaryen\":\"House_Targaryen\",\"House_Lannister\":'House_Lannister',\"House_Greyjoy\":'House_Greyjoy',\"House_Tyrell\":'House_Tyrell', \"Other_house\":'Other_house'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cb92c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:05.760826Z",
     "start_time": "2021-12-05T15:35:05.758245Z"
    }
   },
   "outputs": [],
   "source": [
    "#got.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00426f8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:06.411792Z",
     "start_time": "2021-12-05T15:35:06.409613Z"
    }
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "#I use the gender_guesser to guess the gender by the name , however it took a lot of time almost 10 minutes in my macbook pro.\n",
    "##############################################\n",
    "\n",
    "#%pip install gender_guesser\n",
    "#import random as rand \n",
    "#import gender_guesser.detector as gender \n",
    "# placeholder list\n",
    "#placeholder_lst = []\n",
    "\n",
    "\n",
    "# looping to guess gender\n",
    "#for name in got['name']:\n",
    "#    guess = gender.Detector().get_gender(name)\n",
    "#    placeholder_lst.append(guess)\n",
    "\n",
    "\n",
    "# converting list into a series\n",
    "#got['gender_guess'] = pd.Series(placeholder_lst)\n",
    "\n",
    "\n",
    "# checking results\n",
    "#got.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd114961",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:07.074651Z",
     "start_time": "2021-12-05T15:35:07.072493Z"
    }
   },
   "outputs": [],
   "source": [
    "#Most of them unknown almost 100% there is no way to use this new variable in my model\n",
    "#import pandasql as ps\n",
    "#got_query2 = \"\"\"SELECT gender_guess, count(gender_guess) as count_  FROM got group by gender_guess order by #count_ desc\"\"\"\n",
    "#got_guessgender = ps.sqldf(got_query2, locals())\n",
    "#got_guessgender.head(n=10)\n",
    "\n",
    "####################################################\n",
    "#The results were not gret most of them are unknown, there is no point  to use the gender considering the that for the majority we don't know the gender\n",
    "#unknown 1852\n",
    "#male 48\n",
    "#female 37\n",
    "#mostly_female 6\n",
    "#mostly_male 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54e0b06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:07.806869Z",
     "start_time": "2021-12-05T15:35:07.733129Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "#I will get the dummies for house, culture and title\n",
    "dummies = got[\"house\"].str.get_dummies(\" \")\n",
    "got = pd.concat([got, got['house'].str.get_dummies(sep=',')], axis=1) \n",
    "dummies = got[\"culture\"].str.get_dummies(\" \")\n",
    "got = pd.concat([got, got['culture'].str.get_dummies(sep=',')], axis=1) \n",
    "dummies = got[\"title\"].str.get_dummies(\" \")\n",
    "got = pd.concat([got, got['title'].str.get_dummies(sep=',')], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b72b93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:08.383028Z",
     "start_time": "2021-12-05T15:35:08.375661Z"
    }
   },
   "outputs": [],
   "source": [
    "#Checking the rest of the variables there are many which has to many nulls even if we replace them with the mode it would be so unreal, specially mother father heir you cannot replace that value with a mode it shouldnt be right\n",
    "print(got.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5096cdcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:09.077955Z",
     "start_time": "2021-12-05T15:35:09.069084Z"
    }
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# optimal_neighbors\n",
    "########################################\n",
    "def optimal_neighbors(x_data,\n",
    "                      y_data,\n",
    "                      standardize = True,\n",
    "                      pct_test=0.25,\n",
    "                      seed=219,\n",
    "                      response_type='reg',\n",
    "                      max_neighbors=20,\n",
    "                      show_viz=True):\n",
    "    \"\"\"\n",
    "Exhaustively compute training and testing results for KNN across\n",
    "[1, max_neighbors]. Outputs the maximum test score and (by default) a\n",
    "visualization of the results.\n",
    "PARAMETERS\n",
    "----------\n",
    "x_data        : explanatory variable data\n",
    "y_data        : response variable\n",
    "standardize   : whether or not to standardize the x data, default True\n",
    "pct_test      : test size for training and validation from (0,1), default 0.25\n",
    "seed          : random seed to be used in algorithm, default 219\n",
    "response_type : type of neighbors algorithm to use, default 'reg'\n",
    "    Use 'reg' for regression (KNeighborsRegressor)\n",
    "    Use 'class' for classification (KNeighborsClassifier)\n",
    "max_neighbors : maximum number of neighbors in exhaustive search, default 20\n",
    "show_viz      : display or surpress k-neigbors visualization, default True\n",
    "\"\"\"    \n",
    "    \n",
    "    \n",
    "    if standardize == True:\n",
    "        # optionally standardizing x_data\n",
    "        scaler             = StandardScaler()\n",
    "        scaler.fit(x_data)\n",
    "        x_scaled           = scaler.transform(x_data)\n",
    "        x_scaled_df        = pd.DataFrame(x_scaled)\n",
    "        x_data             = x_scaled_df\n",
    "\n",
    "\n",
    "\n",
    "    # train-test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data,\n",
    "                                                        y_data,\n",
    "                                                        test_size = pct_test,\n",
    "                                                        random_state = seed)\n",
    "\n",
    "\n",
    "    # creating lists for training set accuracy and test set accuracy\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    \n",
    "    # setting neighbor range\n",
    "    neighbors_settings = range(1, max_neighbors + 1)\n",
    "\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        # building the model based on response variable type\n",
    "        if response_type == 'reg':\n",
    "            clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)\n",
    "            \n",
    "        elif response_type == 'class':\n",
    "            clf = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)            \n",
    "            \n",
    "        else:\n",
    "            print(\"Error: response_type must be 'reg' or 'class'\")\n",
    "        \n",
    "        \n",
    "        # recording the training set accuracy\n",
    "        training_accuracy.append(clf.score(x_train, y_train))\n",
    "    \n",
    "        # recording the generalization accuracy\n",
    "        test_accuracy.append(clf.score(x_test, y_test))\n",
    "\n",
    "\n",
    "    # optionally displaying visualization\n",
    "    if show_viz == True:\n",
    "        # plotting the visualization\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "        plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "        plt.plot(neighbors_settings, test_accuracy, label = \"test accuracy\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"n_neighbors\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    # returning optimal number of neighbors\n",
    "    print(f\"The optimal number of neighbors is: {test_accuracy.index(max(test_accuracy))+1}\")\n",
    "    return test_accuracy.index(max(test_accuracy))+1\n",
    "\n",
    "\n",
    "########################################\n",
    "# visual_cm\n",
    "########################################\n",
    "def visual_cm(true_y, pred_y, labels = None):\n",
    "    \"\"\"\n",
    "Creates a visualization of a confusion matrix.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "true_y : true values for the response variable\n",
    "pred_y : predicted values for the response variable\n",
    "labels : , default None\n",
    "    \"\"\"\n",
    "    # visualizing the confusion matrix\n",
    "\n",
    "    # setting labels\n",
    "    lbls = labels\n",
    "    \n",
    "\n",
    "    # declaring a confusion matrix object\n",
    "    cm = confusion_matrix(y_true = true_y,\n",
    "                          y_pred = pred_y)\n",
    "\n",
    "\n",
    "    # heatmap\n",
    "    sns.heatmap(cm,\n",
    "                annot       = True,\n",
    "                xticklabels = lbls,\n",
    "                yticklabels = lbls,\n",
    "                cmap        = 'Blues',\n",
    "                fmt         = 'g')\n",
    "\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix of the Classifier')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f7d609",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:09.754407Z",
     "start_time": "2021-12-05T15:35:09.752442Z"
    }
   },
   "outputs": [],
   "source": [
    "#Correlation Analysis\n",
    "#df_corr = got.corr(method='pearson').round(decimals=2)\n",
    "#df_corr['isAlive'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0809872",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:10.409255Z",
     "start_time": "2021-12-05T15:35:10.403418Z"
    }
   },
   "outputs": [],
   "source": [
    "#Stratifying the Response Variable\n",
    "got.loc[ : ,'isAlive'].value_counts(normalize = True).round(decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de0ec12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:11.058575Z",
     "start_time": "2021-12-05T15:35:11.052825Z"
    }
   },
   "outputs": [],
   "source": [
    "#Preparing Explanatory and Response Data\n",
    "# declaring explanatory variables\n",
    "got_data = got.drop('isAlive',axis=1)\n",
    "# declaring response variable\n",
    "got_target = got.loc[:, \"isAlive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02182c3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:11.723885Z",
     "start_time": "2021-12-05T15:35:11.711281Z"
    }
   },
   "outputs": [],
   "source": [
    "#Prepare train-test split for statsmodels.\n",
    "# train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            got_data,\n",
    "            got_target,\n",
    "            test_size    = 0.10,\n",
    "            random_state = 219,\n",
    "            stratify     = got_target) # preserving balance\n",
    "# merging training data for statsmodels\n",
    "got_train = pd.concat([X_train, y_train], axis = 1)\n",
    "\n",
    "print(f\"\"\"\n",
    "\n",
    "Response Variable Proportions (Training Set)\n",
    "--------------------------------------------\n",
    "{y_train.value_counts(normalize = True).round(decimals = 2)}\n",
    "\n",
    "\n",
    "\n",
    "Response Variable Proportions (Testing Set)\n",
    "--------------------------------------------\n",
    "{y_test.value_counts(normalize = True).round(decimals = 2)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b349f2a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:12.434057Z",
     "start_time": "2021-12-05T15:35:12.385599Z"
    }
   },
   "outputs": [],
   "source": [
    "#Build a Univariate Logistic Regression Model\n",
    "# instantiating a logistic regression model object\n",
    "logistic_small = smf.logit(formula   = \"\"\"isAlive~popularity\"\"\",\n",
    "                           data = got_train)\n",
    "# FITTING the model object\n",
    "results_logistic = logistic_small.fit()\n",
    "# checking the results SUMMARY\n",
    "results_logistic.summary2() # summary2() has AIC and BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d378f36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:13.060430Z",
     "start_time": "2021-12-05T15:35:13.027191Z"
    }
   },
   "outputs": [],
   "source": [
    "#To copy and paste the variables easily into your model\n",
    "for val in got_data:\n",
    "    print(f\" {val} + \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c2283b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:13.796883Z",
     "start_time": "2021-12-05T15:35:13.681313Z"
    }
   },
   "outputs": [],
   "source": [
    "# We are using variables with zero nulls observations\n",
    "#We eliminate house tyrrel because they are the house with less members \n",
    "#I elminate Bravosi because that culture has the fewest members\n",
    "#I elminate Maester because that title has the fewest members\n",
    "#I eliminate the first book BOOK1\n",
    "logistic_full = smf.logit(formula = \"\"\"isAlive ~\n",
    "                                     over_agemean +\n",
    "                                     isAliveMother + \n",
    "                                     isAliveFather + \n",
    "                                     isAliveHeir + \n",
    "                                     isAliveSpouse +\n",
    "                                     Free_Folk + \n",
    "                                     Ironborn + \n",
    "                                     Northmen + \n",
    "                                     Other_culture +\n",
    "                                     Valyrian +\n",
    "                                     Other_title +\n",
    "                                     Ser + \n",
    "                                     book2_A_Clash_Of_Kings +\n",
    "                                     book3_A_Storm_Of_Swords +\n",
    "                                     book4_A_Feast_For_Crows +\n",
    "                                     book5_A_Dance_with_Dragons +\n",
    "                                     isMarried +\n",
    "                                     isNoble +\n",
    "                                     numDeadRelations +\n",
    "                                     popularity +\n",
    "                                     House_Frey + \n",
    "                                     House_Greyjoy + \n",
    "                                     House_Lannister + \n",
    "                                     House_Stark + \n",
    "                                     House_Targaryen + \n",
    "                                     Night_Watch +\n",
    "                                     Other_house\"\"\",\n",
    "                                     data    = got_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "results_full = logistic_full.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_full.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce366d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:14.396767Z",
     "start_time": "2021-12-05T15:35:14.343171Z"
    }
   },
   "outputs": [],
   "source": [
    "#Develop a model where all features are significant based on their p-values\n",
    "logit_sig = smf.logit(formula = \"\"\"isAlive ~\n",
    "                                     over_agemean +\n",
    "                                     Free_Folk +\n",
    "                                     Valyrian +\n",
    "                                     book2_A_Clash_Of_Kings +\n",
    "                                     book4_A_Feast_For_Crows +\n",
    "                                     isNoble +\n",
    "                                     popularity +\n",
    "                                     House_Greyjoy +\n",
    "                                     House_Lannister + \n",
    "                                     House_Targaryen + \n",
    "                                     Night_Watch +\n",
    "                                     Other_house\"\"\",\n",
    "                                     data    = got_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "logit_sig = logit_sig.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "logit_sig.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666459f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:15.040392Z",
     "start_time": "2021-12-05T15:35:14.991969Z"
    }
   },
   "outputs": [],
   "source": [
    "#Develop a model where all features are significant based on their p-values\n",
    "logit_sig2 = smf.logit(formula = \"\"\"isAlive ~\n",
    "                                     over_agemean +\n",
    "                                     Free_Folk +\n",
    "                                     Valyrian +\n",
    "                                     book2_A_Clash_Of_Kings +\n",
    "                                     book4_A_Feast_For_Crows +\n",
    "                                     popularity +\n",
    "                                     House_Greyjoy +\n",
    "                                     House_Lannister + \n",
    "                                     House_Targaryen + \n",
    "                                     Night_Watch +\n",
    "                                     Other_house\"\"\",\n",
    "                                     data    = got_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "logit_sig2 = logit_sig2.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "logit_sig2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7c5dc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:15.644989Z",
     "start_time": "2021-12-05T15:35:15.641687Z"
    }
   },
   "outputs": [],
   "source": [
    "# Logistic in scikit-learn\n",
    "# creating a dictionary to store candidate models\n",
    "candidate_dict = {\n",
    "    \n",
    " # significant variables only (set 2)\n",
    " 'logit_sig_2'  : [ 'over_agemean','Free_Folk', 'Valyrian', 'book2_A_Clash_Of_Kings',\n",
    "                   'book4_A_Feast_For_Crows', 'popularity', 'House_Greyjoy', 'House_Lannister', 'House_Targaryen', 'Night_Watch', 'Other_house']\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd3f305",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:16.350258Z",
     "start_time": "2021-12-05T15:35:16.311381Z"
    }
   },
   "outputs": [],
   "source": [
    "#Logistic with sckli\n",
    "# train/test split with the model with all variables with a p value significant\n",
    "got_data   =  got.loc[ : , candidate_dict['logit_sig_2']]\n",
    "got_target =  got.loc[ : , 'isAlive']\n",
    "\n",
    "\n",
    "# this is the exact code we were using before\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            got_data,\n",
    "            got_target,\n",
    "            random_state = 219,\n",
    "            test_size    = 0.10,\n",
    "            stratify     = got_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 1,\n",
    "                            random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('LogReg Training ACCURACY:', logreg_fit.score(x_train, y_train).round(4))\n",
    "print('LogReg Testing  ACCURACY:', logreg_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = logreg_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('LogReg Train-Test Gap   :', abs(logreg_train_score - logreg_test_score).round(4))\n",
    "logreg_test_gap = abs(logreg_train_score - logreg_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0379435e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:16.978373Z",
     "start_time": "2021-12-05T15:35:16.973596Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating a confusion matrix\n",
    "print(confusion_matrix(y_true = y_test,\n",
    "                       y_pred = logreg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88e8e52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:17.645080Z",
     "start_time": "2021-12-05T15:35:17.639933Z"
    }
   },
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "logreg_tn, \\\n",
    "logreg_fp, \\\n",
    "logreg_fn, \\\n",
    "logreg_tp = confusion_matrix(y_true = y_test, y_pred = logreg_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {logreg_tn}\n",
    "False Positives: {logreg_fp}\n",
    "False Negatives: {logreg_fn}\n",
    "True Positives : {logreg_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7213c3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:18.320620Z",
     "start_time": "2021-12-05T15:35:18.313538Z"
    }
   },
   "outputs": [],
   "source": [
    "# area under the roc curve (auc)\n",
    "print(roc_auc_score(y_true  = y_test,\n",
    "                    y_score = logreg_pred).round(decimals = 4))\n",
    "\n",
    "\n",
    "# saving AUC score for future use\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = logreg_pred).round(decimals = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeb712d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:18.999910Z",
     "start_time": "2021-12-05T15:35:18.984428Z"
    }
   },
   "outputs": [],
   "source": [
    "# zipping each feature name to its coefficient\n",
    "logreg_model_values = zip(got[candidate_dict['logit_sig_2']].columns,\n",
    "                          logreg_fit.coef_.ravel().round(decimals = 2))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "logreg_model_lst = [('intercept', logreg_fit.intercept_[0].round(decimals = 2))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in logreg_model_values:\n",
    "    logreg_model_lst.append(val)\n",
    "    \n",
    "\n",
    "# checking the results\n",
    "for pair in logreg_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25567b39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:19.654957Z",
     "start_time": "2021-12-05T15:35:19.650944Z"
    }
   },
   "outputs": [],
   "source": [
    "########Classification trees\n",
    "\n",
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances(model, train, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = x_train.shape[1]\n",
    "    \n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('Tree_Leaf_50_Feature_Importance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d53b50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:20.356675Z",
     "start_time": "2021-12-05T15:35:20.326577Z"
    }
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "full_tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "full_tree_fit = full_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "full_tree_pred = full_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Full Tree Training ACCURACY:', full_tree_fit.score(x_train,\n",
    "                                                     y_train).round(4))\n",
    "\n",
    "print('Full Tree Testing ACCURACY :', full_tree_fit.score(x_test,\n",
    "                                                     y_test).round(4))\n",
    "\n",
    "print('Full Tree AUC Score:', roc_auc_score(y_true  = y_test,\n",
    "                                            y_score = full_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "full_tree_train_score = full_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "full_tree_test_score  = full_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('LogReg Train-Test Gap   :', abs(full_tree_train_score - full_tree_test_score).round(4))\n",
    "full_tree_test_gap = abs(full_tree_train_score - full_tree_test_score).round(4)\n",
    "\n",
    "# saving AUC\n",
    "full_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                      y_score = full_tree_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1d277a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:21.002045Z",
     "start_time": "2021-12-05T15:35:20.996768Z"
    }
   },
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "full_tree_tn, \\\n",
    "full_tree_fp, \\\n",
    "full_tree_fn, \\\n",
    "full_tree_tp = confusion_matrix(y_true = y_test, y_pred = full_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {full_tree_tn}\n",
    "False Positives: {full_tree_fp}\n",
    "False Negatives: {full_tree_fn}\n",
    "True Positives : {full_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615a2d33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:21.665471Z",
     "start_time": "2021-12-05T15:35:21.663411Z"
    }
   },
   "outputs": [],
   "source": [
    "# setting figure size\n",
    "#plt.figure(figsize=(150,50))\n",
    "\n",
    "\n",
    "# developing a plotted tree\n",
    "#plot_tree(decision_tree = full_tree_fit, \n",
    "#          feature_names = got.columns,\n",
    "#          filled        = True, \n",
    "#          rounded       = True, \n",
    "#          fontsize      = 14)\n",
    "\n",
    "\n",
    "# rendering the plot\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca77b65f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:22.374316Z",
     "start_time": "2021-12-05T15:35:22.343834Z"
    }
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "pruned_tree = DecisionTreeClassifier(max_depth = 4,\n",
    "                                     min_samples_leaf = 25,\n",
    "                                     random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "pruned_tree_fit  = pruned_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "pruned_tree_pred = pruned_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', pruned_tree_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', pruned_tree_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = pruned_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "pruned_tree_train_score = pruned_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "pruned_tree_test_score  = pruned_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('LogReg Train-Test Gap   :', abs(pruned_tree_train_score - pruned_tree_test_score).round(4))\n",
    "pruned_tree_test_gap = abs(pruned_tree_train_score - pruned_tree_test_score).round(4)\n",
    "\n",
    "# saving auc score\n",
    "pruned_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                        y_score = pruned_tree_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cd4fcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:23.013903Z",
     "start_time": "2021-12-05T15:35:23.008851Z"
    }
   },
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "pruned_tree_tn, \\\n",
    "pruned_tree_fp, \\\n",
    "pruned_tree_fn, \\\n",
    "pruned_tree_tp = confusion_matrix(y_true = y_test, y_pred = pruned_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {pruned_tree_tn}\n",
    "False Positives: {pruned_tree_fp}\n",
    "False Negatives: {pruned_tree_fn}\n",
    "True Positives : {pruned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a7a4f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:23.674858Z",
     "start_time": "2021-12-05T15:35:23.672740Z"
    }
   },
   "outputs": [],
   "source": [
    "# setting figure size\n",
    "#plt.figure(figsize=(20, 10)) # adjusting to better fit the visual\n",
    "\n",
    "\n",
    "# developing a plotted tree\n",
    "#plot_tree(decision_tree = pruned_tree_fit, # changing to pruned_tree_fit\n",
    "#          feature_names = got.columns,\n",
    "#          filled        = True, \n",
    "#          rounded       = True, \n",
    "#          fontsize      = 14)\n",
    "\n",
    "\n",
    "\n",
    "# rendering the plot\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca36f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:24.495297Z",
     "start_time": "2021-12-05T15:35:24.329693Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# plotting feature importance\n",
    "plot_feature_importances(pruned_tree_fit,\n",
    "                         train = x_train,\n",
    "                         export = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b62359",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:24.986638Z",
     "start_time": "2021-12-05T15:35:24.981816Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating a dictionary for model results\n",
    "model_performance = {\n",
    "    \n",
    "    'Model Name'    : ['Logistic', 'Full Tree', 'Pruned Tree'],\n",
    "           \n",
    "    'AUC Score' : [logreg_auc_score, full_tree_auc_score, pruned_tree_auc_score],\n",
    "    \n",
    "    'Training Accuracy' : [logreg_train_score, full_tree_train_score,\n",
    "                           pruned_tree_train_score],\n",
    "           \n",
    "    'Testing Accuracy'  : [logreg_test_score, full_tree_test_score,\n",
    "                           pruned_tree_test_score],\n",
    "\n",
    "    'GAP TRAINING - TEST SCORE'  : [logreg_test_gap, full_tree_test_gap,\n",
    "                           pruned_tree_test_gap],\n",
    "    \n",
    "    'Confusion Matrix'  : [(logreg_tn, logreg_fp, logreg_fn, logreg_tp),\n",
    "                           (full_tree_tn, full_tree_fp, full_tree_fn, full_tree_tp),\n",
    "                           (pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp)]}\n",
    "\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "model_performance = pd.DataFrame(model_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508c2996",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:25.653599Z",
     "start_time": "2021-12-05T15:35:25.651007Z"
    }
   },
   "outputs": [],
   "source": [
    "#We store this variables to try a new model with the feature importance relevant\n",
    "candidate_dict_feature_importance = {\n",
    " 'logit_sig_3'  : ['over_agemean','book4_A_Feast_For_Crows', 'popularity',\n",
    "                    'Night_Watch','Other_house']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d556d1df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:26.320389Z",
     "start_time": "2021-12-05T15:35:26.312901Z"
    }
   },
   "outputs": [],
   "source": [
    "# train/test split with the model with all variables with a feature importance\n",
    "got_data_fi   =  got.loc[ : , candidate_dict_feature_importance['logit_sig_3']]\n",
    "got_target_fi =  got.loc[ : , 'isAlive']\n",
    "\n",
    "\n",
    "# this is the exact code we were using before\n",
    "x_train_fi, x_test_fi, y_train_fi, y_test_fi = train_test_split(\n",
    "            got_data_fi,\n",
    "            got_target_fi,\n",
    "            random_state = 219,\n",
    "            test_size    = 0.10,\n",
    "            stratify     = got_target_fi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb4660",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:26.988161Z",
     "start_time": "2021-12-05T15:35:26.984844Z"
    }
   },
   "outputs": [],
   "source": [
    "#Hyperparameter Tuning\n",
    "########################################\n",
    "# importing packages\n",
    "########################################\n",
    "import matplotlib.pyplot as plt                      # data visualization\n",
    "import pandas as pd                                  # data science essentials\n",
    "from sklearn.model_selection import train_test_split # train-test split\n",
    "from sklearn.linear_model import LogisticRegression  # logistic regression\n",
    "from sklearn.metrics import roc_auc_score            # auc score\n",
    "from sklearn.metrics import confusion_matrix         # confusion matrix\n",
    "\n",
    "\n",
    "# CART model packages\n",
    "from sklearn.tree import DecisionTreeClassifier      # classification trees\n",
    "from sklearn.tree import plot_tree                   # tree plots\n",
    "\n",
    "\n",
    "# new packages\n",
    "from sklearn.model_selection import RandomizedSearchCV     # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer              # customizable scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc70b66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:27.654568Z",
     "start_time": "2021-12-05T15:35:27.646145Z"
    }
   },
   "outputs": [],
   "source": [
    "# train/test split with the second model with all p values significant\n",
    "got_data   =  got.loc[ : , candidate_dict['logit_sig_2']]\n",
    "got_target =  got.loc[ : , 'isAlive']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            got_data,\n",
    "            got_target,\n",
    "            random_state = 219,\n",
    "            test_size    = 0.10,\n",
    "            stratify     = got_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5499a0db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:28.313082Z",
     "start_time": "2021-12-05T15:35:28.310690Z"
    }
   },
   "outputs": [],
   "source": [
    "#Logistic Regression with Default Hyperparameters\n",
    "lr_default = LogisticRegression(solver = 'lbfgs',\n",
    "                                C = 1.0,\n",
    "                                warm_start = False,\n",
    "                                random_state = 219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e901303b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:29.026608Z",
     "start_time": "2021-12-05T15:35:28.983236Z"
    }
   },
   "outputs": [],
   "source": [
    "# FITTING the training data\n",
    "lr_default_fit = lr_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "lr_default_pred = lr_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', lr_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', lr_default_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# SCORING with AUC\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = lr_default_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = lr_default_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = lr_default_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('LogReg Train-Test Gap   :', abs(pruned_tree_train_score - pruned_tree_test_score).round(4))\n",
    "pruned_tree_test_gap = abs(pruned_tree_train_score - pruned_tree_test_score).round(4)\n",
    "\n",
    "# saving AUC score\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = lr_default_pred).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b4392c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:29.631197Z",
     "start_time": "2021-12-05T15:35:29.629041Z"
    }
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# RandomizedSearchCV\n",
    "########################################\n",
    "\n",
    "# declaring a hyperparameter space\n",
    "#C_range          = np.arange(0.1, 5.0, 0.1)\n",
    "#warm_start_range = [True, False]\n",
    "#solver_range     = ['newton-cg', 'sag', 'lbfgs']\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "#param_grid = {'C'          : C_range,\n",
    "#              'warm_start' : warm_start_range,\n",
    "#              'solver'     : solver_range}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "#lr_tuned = LogisticRegression(random_state = 219,\n",
    " #                             max_iter     = 1000) # increased for convergence\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "#lr_tuned_cv = RandomizedSearchCV(estimator           = lr_tuned,   # the model object\n",
    "#                                 param_distributions = param_grid, # parameters to tune\n",
    " #                                cv                  = 3,          # how many folds in cross-validation\n",
    "  #                               n_iter              = 250,        # number of combinations of hyperparameters to try\n",
    "   #                              random_state        = 219,        # starting point for random sequence\n",
    "    #                             scoring = make_scorer(\n",
    "    #                                       roc_auc_score,\n",
    "    #                                       needs_threshold = False)) # scoring criteria (AUC)\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "#lr_tuned_cv.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "#print(\"Tuned Parameters  :\", lr_tuned_cv.best_params_)\n",
    "#print(\"Tuned CV AUC      :\", lr_tuned_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9c9774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:30.287255Z",
     "start_time": "2021-12-05T15:35:30.285451Z"
    }
   },
   "outputs": [],
   "source": [
    "#lr_tuned_cv.best_estimator_\n",
    "#Results\n",
    "#LogisticRegression(C=1.6, max_iter=1000, random_state=219, solver='newton-cg',\n",
    "#                   warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80ded2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:30.998963Z",
     "start_time": "2021-12-05T15:35:30.953373Z"
    }
   },
   "outputs": [],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING a logistic regression model with tuned values\n",
    "lr_tuned = LogisticRegression(C            = 1.6,\n",
    "                              warm_start   = True,\n",
    "                              solver       = 'newton-cg',\n",
    "                              max_iter     = 1000,\n",
    "                              random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the model to the full dataset\n",
    "lr_tuned.fit(got_data, got_target) # this is ok because already tuned\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "lr_tuned_pred = lr_tuned.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('LR Tuned Training ACCURACY:', lr_tuned.score(x_train, y_train).round(4))\n",
    "print('LR Tuned Testing  ACCURACY:', lr_tuned.score(x_test, y_test).round(4))\n",
    "print('LR Tuned AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = lr_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "lr_tuned_train_score = lr_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "lr_tuned_test_score  = lr_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('LR Tuned Train-Test Gap   :', abs(lr_tuned_train_score - lr_tuned_test_score).round(4))\n",
    "lr_tuned_tree_test_gap = abs(lr_tuned_train_score - lr_tuned_test_score).round(4)\n",
    "\n",
    "# saving the AUC score\n",
    "lr_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                     y_score = lr_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6896c229",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:31.605094Z",
     "start_time": "2021-12-05T15:35:31.600249Z"
    }
   },
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "lr_tuned_tn, \\\n",
    "lr_tuned_fp, \\\n",
    "lr_tuned_fn, \\\n",
    "lr_tuned_tp = confusion_matrix(y_true = y_test, y_pred = lr_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {lr_tuned_tn}\n",
    "False Positives: {lr_tuned_fp}\n",
    "False Negatives: {lr_tuned_fn}\n",
    "True Positives : {lr_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a51d27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:32.294472Z",
     "start_time": "2021-12-05T15:35:32.280588Z"
    }
   },
   "outputs": [],
   "source": [
    "# declaring model performance objects\n",
    "lr_train_acc = lr_tuned.score(x_train, y_train).round(4)\n",
    "lr_test_acc  = lr_tuned.score(x_test, y_test).round(4)\n",
    "lr_auc       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = lr_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Tuned LR',\n",
    "                           'Training Accuracy' : lr_train_acc,\n",
    "                           'Testing Accuracy'  : lr_test_acc,\n",
    "                           'AUC Score'         : lr_auc,\n",
    "                           'GAP TRAINING - TEST SCORE'         : lr_tuned_tree_test_gap,\n",
    "                           'Confusion Matrix'  : (lr_tuned_tn,\n",
    "                                                  lr_tuned_fp,\n",
    "                                                  lr_tuned_fn,\n",
    "                                                  lr_tuned_tp)},\n",
    "                           ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "#model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab96ba51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:32.933921Z",
     "start_time": "2021-12-05T15:35:32.931626Z"
    }
   },
   "outputs": [],
   "source": [
    "#Hyperparameter Tuning on Classification Trees\n",
    "# declaring a hyperparameter space\n",
    "#criterion_range = ['gini', 'entropy']\n",
    "#splitter_range  = ['best', 'random']\n",
    "#depth_range     = np.arange(1, 25, 1)\n",
    "#leaf_range      = np.arange(1, 100, 1)\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "#param_grid = {'criterion'        : criterion_range,\n",
    "#              'splitter'         : splitter_range,\n",
    "#              'max_depth'        : depth_range,\n",
    "#              'min_samples_leaf' : leaf_range}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "#tuned_tree = DecisionTreeClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# RandomizedSearchCV object\n",
    "#tuned_tree_cv = RandomizedSearchCV(estimator             = tuned_tree,\n",
    "#                                   param_distributions   = param_grid,\n",
    "#                                   cv                    = 3,\n",
    "#                                   n_iter                = 1000,\n",
    "#                                   random_state          = 219,\n",
    "#                                   scoring = make_scorer(roc_auc_score,\n",
    "#                                             needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "#tuned_tree_cv.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "#print(\"Tuned Parameters  :\", tuned_tree_cv.best_params_)\n",
    "#print(\"Tuned Training AUC:\", tuned_tree_cv.best_score_.round(4))\n",
    "#Tuned Parameters  : {'splitter': 'random', 'min_samples_leaf': 2, 'max_depth': 14, 'criterion': 'gini'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f852dc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:33.637398Z",
     "start_time": "2021-12-05T15:35:33.609506Z"
    }
   },
   "outputs": [],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING a logistic regression model with tuned values\n",
    "tree_tuned = DecisionTreeClassifier(splitter         = 'random',\n",
    "                                    min_samples_leaf = 2,\n",
    "                                    max_depth        = 8,#the rules of the assignment said set a maximum of 8\n",
    "                                    criterion        = 'gini',\n",
    "                                    random_state     = 219)\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "tree_tuned_fit = tree_tuned.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "tree_tuned_pred = tree_tuned.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', tree_tuned.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_tuned.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "tree_tuned_train_score = tree_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "tree_tuned_test_score  = tree_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('tree_tuned Train-Test Gap   :', abs(tree_tuned_train_score - tree_tuned_test_score).round(4))\n",
    "tree_tuned_tree_test_gap = abs(tree_tuned_train_score - tree_tuned_test_score).round(4)\n",
    "\n",
    "# saving the AUC score\n",
    "tree_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                       y_score = tree_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f135e50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:34.283266Z",
     "start_time": "2021-12-05T15:35:34.277712Z"
    }
   },
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "tuned_tree_tn, \\\n",
    "tuned_tree_fp, \\\n",
    "tuned_tree_fn, \\\n",
    "tuned_tree_tp = confusion_matrix(y_true = y_test, y_pred = tree_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_tree_tn}\n",
    "False Positives: {tuned_tree_fp}\n",
    "False Negatives: {tuned_tree_fn}\n",
    "True Positives : {tuned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aeef01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:34.963379Z",
     "start_time": "2021-12-05T15:35:34.950692Z"
    }
   },
   "outputs": [],
   "source": [
    "# declaring model performance objects\n",
    "tree_train_acc = tree_tuned.score(x_train, y_train).round(4)\n",
    "tree_test_acc  = tree_tuned.score(x_test, y_test).round(4)\n",
    "tree_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = tree_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Tuned Tree',\n",
    "                           'Training Accuracy' : tree_train_acc,\n",
    "                           'Testing Accuracy'  : tree_test_acc,\n",
    "                           'GAP TRAINING - TEST SCORE'         : tree_tuned_tree_test_gap,\n",
    "                           'AUC Score'         : tree_auc,\n",
    "                           'Confusion Matrix'  : (tuned_tree_tn,\n",
    "                                                  tuned_tree_fp,\n",
    "                                                  tuned_tree_fn,\n",
    "                                                  tuned_tree_tp)},\n",
    "                           ignore_index = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f31b44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:35.631016Z",
     "start_time": "2021-12-05T15:35:35.628816Z"
    }
   },
   "outputs": [],
   "source": [
    "#Hyperparameter Tuning on Classification Trees\n",
    "# declaring a hyperparameter space\n",
    "#criterion_range = ['gini', 'entropy']\n",
    "#splitter_range  = ['best', 'random']\n",
    "#depth_range     = np.arange(1, 25, 1)\n",
    "#leaf_range      = np.arange(1, 100, 1)\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "#param_grid = {'criterion'        : criterion_range,\n",
    "#              'splitter'         : splitter_range,\n",
    "#              'max_depth'        : depth_range,\n",
    "#              'min_samples_leaf' : leaf_range}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "#tuned_tree = DecisionTreeClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# RandomizedSearchCV object\n",
    "#tuned_tree_fi_cv = RandomizedSearchCV(estimator             = tuned_tree,\n",
    "#                                   param_distributions   = param_grid,\n",
    "#                                   cv                    = 3,\n",
    "#                                   n_iter                = 1000,\n",
    "#                                   random_state          = 219,\n",
    "#                                   scoring = make_scorer(roc_auc_score,\n",
    "#                                             needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "#tuned_tree_fi_cv.fit(got_data_fi, got_target_fi)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "#print(\"Tuned Parameters  :\", tuned_tree_fi_cv.best_params_)\n",
    "#print(\"Tuned Training AUC:\", tuned_tree_fi_cv.best_score_.round(4))\n",
    "#Tuned Parameters  : {'splitter': 'best', 'min_samples_leaf': 36, 'max_depth': 4, 'criterion': 'gini'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef94bedb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:36.348483Z",
     "start_time": "2021-12-05T15:35:36.319298Z"
    }
   },
   "outputs": [],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING a logistic regression model with tuned values\n",
    "tree_tuned_fi = DecisionTreeClassifier(splitter         = 'best',\n",
    "                                    min_samples_leaf = 36,\n",
    "                                    max_depth        = 4,\n",
    "                                    criterion        = 'gini',\n",
    "                                    random_state     = 219)\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "tree_tuned_fit = tree_tuned_fi.fit(got_data_fi, got_target_fi)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "tree_tuned_pred_fi = tree_tuned_fi.predict(x_test_fi)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', tree_tuned_fi.score(x_train_fi, y_train_fi).round(4))\n",
    "print('Testing  ACCURACY:', tree_tuned_fi.score(x_test_fi, y_test_fi).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test_fi,\n",
    "                                          y_score = tree_tuned_pred_fi).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "tree_tuned_fi_train_score = tree_tuned_fi.score(x_train_fi, y_train_fi).round(4) # accuracy\n",
    "tree_tuned_fi_test_score  = tree_tuned_fi.score(x_test_fi, y_test_fi).round(4)   # accuracy\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('tree_tuned_fi Train-Test Gap   :', abs(tree_tuned_fi_train_score - tree_tuned_fi_test_score).round(4))\n",
    "tree_tuned_fi_tree_test_gap = abs(tree_tuned_fi_train_score - tree_tuned_fi_test_score).round(4)\n",
    "\n",
    "# saving the AUC score\n",
    "tree_tuned_fi_auc         = roc_auc_score(y_true  = y_test_fi,\n",
    "                                       y_score = tree_tuned_pred_fi).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c171b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:37.006674Z",
     "start_time": "2021-12-05T15:35:37.001324Z"
    }
   },
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "tuned_tree_fi_tn, \\\n",
    "tuned_tree_fi_fp, \\\n",
    "tuned_tree_fi_fn, \\\n",
    "tuned_tree_fi_tp = confusion_matrix(y_true = y_test_fi, y_pred = tree_tuned_pred_fi).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_tree_fi_tn}\n",
    "False Positives: {tuned_tree_fi_fp}\n",
    "False Negatives: {tuned_tree_fi_fn}\n",
    "True Positives : {tuned_tree_fi_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b192fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:37.694603Z",
     "start_time": "2021-12-05T15:35:37.681089Z"
    }
   },
   "outputs": [],
   "source": [
    "# declaring model performance objects\n",
    "tree_train_acc_fi = tree_tuned_fi.score(x_train_fi, y_train_fi).round(4)\n",
    "tree_test_acc_fi  = tree_tuned_fi.score(x_test_fi, y_test_fi).round(4)\n",
    "tree_auc_fi       = roc_auc_score(y_true  = y_test_fi,\n",
    "                              y_score = tree_tuned_pred_fi).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Tuned Tree FI',\n",
    "                           'Training Accuracy' : tree_train_acc_fi,\n",
    "                           'Testing Accuracy'  : tree_test_acc_fi,\n",
    "                           'GAP TRAINING - TEST SCORE'         : tree_tuned_fi_tree_test_gap,\n",
    "                           'AUC Score'         : tree_tuned_fi_auc,\n",
    "                           'Confusion Matrix'  : (tuned_tree_fi_tn,\n",
    "                                                  tuned_tree_fi_fp,\n",
    "                                                  tuned_tree_fi_fn,\n",
    "                                                  tuned_tree_fi_tp)},\n",
    "                           ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6975355d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:38.366425Z",
     "start_time": "2021-12-05T15:35:38.347904Z"
    }
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a random forest model with default values\n",
    "from sklearn.ensemble import RandomForestClassifier     # random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gbm\n",
    "rf_default = RandomForestClassifier(n_estimators     = 100,\n",
    "                                    criterion        = 'gini',\n",
    "                                    max_depth        = None,\n",
    "                                    min_samples_leaf = 1,\n",
    "                                    bootstrap        = True,\n",
    "                                    warm_start       = False,\n",
    "                                    random_state     = 219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c42c90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:39.242918Z",
     "start_time": "2021-12-05T15:35:39.011640Z"
    }
   },
   "outputs": [],
   "source": [
    "# FITTING the training data\n",
    "rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', rf_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', rf_default_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rf_default_fit_pred).round(4))\n",
    "# unpacking the confusion matrix\n",
    "rf_tn, \\\n",
    "rf_fp, \\\n",
    "rf_fn, \\\n",
    "rf_tp = confusion_matrix(y_true = y_test, y_pred = rf_default_fit_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {rf_tn}\n",
    "False Positives: {rf_fp}\n",
    "False Negatives: {rf_fn}\n",
    "True Positives : {rf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d5ce52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:39.820654Z",
     "start_time": "2021-12-05T15:35:39.660272Z"
    }
   },
   "outputs": [],
   "source": [
    "# plotting feature importances\n",
    "plot_feature_importances(rf_default_fit,\n",
    "                         train = x_train,\n",
    "                         export = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddda53d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:40.421960Z",
     "start_time": "2021-12-05T15:35:40.316795Z"
    }
   },
   "outputs": [],
   "source": [
    "# saving scoring data for future use\n",
    "rf_full_train_score = rf_default_fit.score(x_train, y_train).round(4) # accuracy\n",
    "rf_full_test_score  = rf_default_fit.score(x_test, y_test).round(4)  # accuracy\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('FULL GBM Train-Test Gap   :', abs(rf_full_train_score - rf_full_test_score ).round(4))\n",
    "rf_full_tree_test_gap = abs(rf_full_train_score - rf_full_test_score ).round(4)\n",
    "\n",
    "# declaring model performance objects\n",
    "rf_train_acc = rf_default_fit.score(x_train, y_train).round(4)\n",
    "rf_test_acc  = rf_default_fit.score(x_test, y_test).round(4)\n",
    "rf_auc       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = rf_default_fit_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'         : 'Random Forest (Full)',\n",
    "                           'Training Accuracy'  : rf_train_acc,\n",
    "                           'Testing Accuracy'   : rf_test_acc,\n",
    "                           'AUC Score'          : rf_auc,\n",
    "                           'GAP TRAINING - TEST SCORE'         : rf_full_tree_test_gap,\n",
    "                           'Confusion Matrix'   : (rf_tn,\n",
    "                                                   rf_fp,\n",
    "                                                   rf_fn,\n",
    "                                                   rf_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdca2e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:41.109385Z",
     "start_time": "2021-12-05T15:35:40.987498Z"
    }
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING the model object without hyperparameters\n",
    "full_gbm_default = GradientBoostingClassifier(loss          = 'deviance',\n",
    "                                              learning_rate = 0.1,\n",
    "                                              n_estimators  = 100,\n",
    "                                              criterion     = 'friedman_mse',\n",
    "                                              max_depth     = 3,\n",
    "                                              warm_start    = False,\n",
    "                                              random_state  = 219)\n",
    "\n",
    "\n",
    "# FIT step is needed as we are not using .best_estimator\n",
    "full_gbm_default_fit = full_gbm_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "full_gbm_default_pred = full_gbm_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', full_gbm_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing ACCURACY :', full_gbm_default_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = full_gbm_default_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332b7332",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:41.652761Z",
     "start_time": "2021-12-05T15:35:41.647956Z"
    }
   },
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "gbm_default_tn, \\\n",
    "gbm_default_fp, \\\n",
    "gbm_default_fn, \\\n",
    "gbm_default_tp = confusion_matrix(y_true = y_test, y_pred = full_gbm_default_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_default_tn}\n",
    "False Positives: {gbm_default_fp}\n",
    "False Negatives: {gbm_default_fn}\n",
    "True Positives : {gbm_default_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39df1b31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:42.364512Z",
     "start_time": "2021-12-05T15:35:42.327773Z"
    }
   },
   "outputs": [],
   "source": [
    "# saving scoring data for future use\n",
    "gbm_full_train_score = full_gbm_default_fit.score(x_train, y_train).round(4) # accuracy\n",
    "gbm_full_test_score  = full_gbm_default_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('FULL GBM Train-Test Gap   :', abs(gbm_full_train_score - gbm_full_test_score ).round(4))\n",
    "gbm_full_tree_test_gap = abs(gbm_full_train_score - gbm_full_test_score ).round(4)\n",
    "# declaring model performance objects\n",
    "gbm_train_acc = full_gbm_default_fit.score(x_train, y_train).round(4)\n",
    "gbm_test_acc  = full_gbm_default_fit.score(x_test, y_test).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = full_gbm_default_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'       : 'GBM (Full)',\n",
    "                          'Training Accuracy' : gbm_train_acc,\n",
    "                          'Testing Accuracy'  : gbm_test_acc,\n",
    "                          'AUC Score'         : gbm_auc,\n",
    "                          'GAP TRAINING - TEST SCORE'         : gbm_full_tree_test_gap,\n",
    "                          'Confusion Matrix'  : (gbm_default_tn,\n",
    "                                                 gbm_default_fp,\n",
    "                                                 gbm_default_fn,\n",
    "                                                 gbm_default_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae0357a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:43.009735Z",
     "start_time": "2021-12-05T15:35:43.007296Z"
    }
   },
   "outputs": [],
   "source": [
    "# declaring a hyperparameter space\n",
    "#learn_range        = np.arange(0.1, 2.2, 0.5)\n",
    "#estimator_range    = np.arange(100, 501, 25)\n",
    "#depth_range        = np.arange(2, 11, 2)\n",
    "#warm_start_range   = [True, False]\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "#param_grid = {'learning_rate' : learn_range,\n",
    "   #           'max_depth'     : depth_range,\n",
    "  #            'n_estimators'  : estimator_range,\n",
    " #             'warm_start'    : warm_start_range}\n",
    "\n",
    "#\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "#full_gbm_grid = GradientBoostingClassifier(random_state = 219)\n",
    "#\n",
    "#\n",
    "# GridSearchCV object\n",
    "#full_gbm_cv = RandomizedSearchCV(estimator     = full_gbm_grid,\n",
    "    #                       param_distributions = param_grid,\n",
    "   #                        cv                  = 3,\n",
    "  #                         n_iter              = 500,\n",
    " #                          random_state        = 219,\n",
    " #                          scoring             = make_scorer(roc_auc_score,\n",
    " #                                                needs_threshold = False))\n",
    "#\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "#full_gbm_cv.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "#print(\"Tuned Parameters  :\", full_gbm_cv.best_params_)\n",
    "#print(\"Tuned Training AUC:\", full_gbm_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9e461a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:43.683294Z",
     "start_time": "2021-12-05T15:35:43.681017Z"
    }
   },
   "outputs": [],
   "source": [
    "#full_gbm_cv.best_estimator_\n",
    "#GradientBoostingClassifier(learning_rate=1.1, max_depth=2, n_estimators=350,\n",
    "#                           random_state=219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1d4971",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:44.648489Z",
     "start_time": "2021-12-05T15:35:44.354088Z"
    }
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING with best_estimator\n",
    "gbm_tuned = GradientBoostingClassifier(learning_rate = 1.1,\n",
    "                                       max_depth     = 2,\n",
    "                                       n_estimators  = 350,\n",
    "                                       warm_start    = True,\n",
    "                                       random_state  = 219)\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "gbm_tuned_fit = gbm_tuned.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "gbm_tuned_pred = gbm_tuned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', gbm_tuned_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', gbm_tuned_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = gbm_tuned_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b53ae82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:45.003468Z",
     "start_time": "2021-12-05T15:35:44.998414Z"
    }
   },
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "gbm_tuned_tn, \\\n",
    "gbm_tuned_fp, \\\n",
    "gbm_tuned_fn, \\\n",
    "gbm_tuned_tp = confusion_matrix(y_true = y_test, y_pred = gbm_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_tuned_tn}\n",
    "False Positives: {gbm_tuned_fp}\n",
    "False Negatives: {gbm_tuned_fn}\n",
    "True Positives : {gbm_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3346238a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:45.717489Z",
     "start_time": "2021-12-05T15:35:45.677175Z"
    }
   },
   "outputs": [],
   "source": [
    "# saving scoring data for future use\n",
    "gbm_tuned_train_score = gbm_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "gbm_tuned_test_score  = gbm_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('Tuned GBM Train-Test Gap   :', abs(gbm_tuned_train_score - gbm_tuned_test_score ).round(4))\n",
    "gbm_tuned_tree_test_gap = abs(gbm_tuned_train_score - gbm_tuned_test_score ).round(4)\n",
    "# declaring model performance objects\n",
    "gbm_train_acc = gbm_tuned_fit.score(x_train, y_train).round(4)\n",
    "gbm_test_acc  = gbm_tuned_fit.score(x_test, y_test).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = gbm_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Tuned GBM',\n",
    "                          'Training Accuracy'  : gbm_train_acc,\n",
    "                          'Testing Accuracy'   : gbm_test_acc,\n",
    "                          'AUC Score'          : gbm_auc,\n",
    "                           'GAP TRAINING - TEST SCORE'         : gbm_tuned_tree_test_gap,\n",
    "                          'Confusion Matrix'   : (gbm_tuned_tn,\n",
    "                                                  gbm_tuned_fp,\n",
    "                                                  gbm_tuned_fn,\n",
    "                                                  gbm_tuned_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bec599",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T15:35:46.354762Z",
     "start_time": "2021-12-05T15:35:46.349178Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "##############################################################################\n",
    "Finally the model I choose is this one:\n",
    "Model: {gbm_tuned_fit} \n",
    "Training Accuracy: {gbm_train_acc}\n",
    "Testing Accuracy: {gbm_test_acc}\n",
    "GAP TRAINING - TEST SCORE: {gbm_tuned_tree_test_gap}\n",
    "AUC Score: {gbm_auc}\n",
    "Confusion Matrix  : (TN={gbm_tuned_tn},\n",
    "                     FP={tuned_tree_fi_fp},\n",
    "                     FN={gbm_tuned_fn},\n",
    "                     TP={gbm_tuned_tp})\n",
    "##############################################################################\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
